import os
import cv2
import math
import numpy as np
import random
import torch
from scipy import special
from scipy.stats import multivariate_normal
from torchvision.transforms.functional import rgb_to_grayscale

# -------------------------------------------------------------------- #
# --------------------------- blur kernels --------------------------- #
# -------------------------------------------------------------------- #


# --------------------------- util functions --------------------------- #
def sigma_matrix2(sig_x, sig_y, theta):
    """Calculate the rotated sigma matrix (two dimensional matrix).

    Args:
        sig_x (float):
        sig_y (float):
        theta (float): Radian measurement.

    Returns:
        ndarray: Rotated sigma matrix.
    """
    d_matrix = np.array([[sig_x**2, 0], [0, sig_y**2]])
    u_matrix = np.array([[np.cos(theta), -np.sin(theta)], [np.sin(theta), np.cos(theta)]])
    return np.dot(u_matrix, np.dot(d_matrix, u_matrix.T))


def mesh_grid(kernel_size):
    """Generate the mesh grid, centering at zero.

    Args:
        kernel_size (int):

    Returns:
        xy (ndarray): with the shape (kernel_size, kernel_size, 2)
        xx (ndarray): with the shape (kernel_size, kernel_size)
        yy (ndarray): with the shape (kernel_size, kernel_size)
    """
    ax = np.arange(-kernel_size // 2 + 1., kernel_size // 2 + 1.)
    xx, yy = np.meshgrid(ax, ax)
    xy = np.hstack((
        xx.reshape((kernel_size * kernel_size, 1)), 
        yy.reshape(kernel_size * kernel_size, 1))).reshape(kernel_size, kernel_size, 2)
    return xy, xx, yy


def pdf2(sigma_matrix, grid):
    """Calculate PDF of the bivariate Gaussian distribution.

    Args:
        sigma_matrix (ndarray): with the shape (2, 2)
        grid (ndarray): generated by :func:`mesh_grid`,
            with the shape (K, K, 2), K is the kernel size.

    Returns:
        kernel (ndarrray): un-normalized kernel.
    """
    inverse_sigma = np.linalg.inv(sigma_matrix)
    kernel = np.exp(-0.5 * np.sum(np.dot(grid, inverse_sigma) * grid, 2))
    return kernel


def cdf2(d_matrix, grid):
    """Calculate the CDF of the standard bivariate Gaussian distribution.
        Used in skewed Gaussian distribution.

    Args:
        d_matrix (ndarrasy): skew matrix.
        grid (ndarray): generated by :func:`mesh_grid`,
            with the shape (K, K, 2), K is the kernel size.

    Returns:
        cdf (ndarray): skewed cdf.
    """
    rv = multivariate_normal([0, 0], [[1, 0], [0, 1]])
    grid = np.dot(grid, d_matrix)
    cdf = rv.cdf(grid)
    return cdf


def bivariate_Gaussian(kernel_size, sig_x, sig_y, theta, grid=None, isotropic=True):
    """Generate a bivariate isotropic or anisotropic Gaussian kernel.

    In the isotropic mode, only `sig_x` is used. `sig_y` and `theta` is ignored.

    Args:
        kernel_size (int):
        sig_x (float):
        sig_y (float):
        theta (float): Radian measurement.
        grid (ndarray, optional): generated by :func:`mesh_grid`,
            with the shape (K, K, 2), K is the kernel size. Default: None
        isotropic (bool):

    Returns:
        kernel (ndarray): normalized kernel.
    """
    if grid is None:
        grid, _, _ = mesh_grid(kernel_size)
    if isotropic:
        sigma_matrix = np.array([[sig_x**2, 0], [0, sig_x**2]])
    else:
        sigma_matrix = sigma_matrix2(sig_x, sig_y, theta)
    kernel = pdf2(sigma_matrix, grid)
    kernel = kernel / np.sum(kernel)
    return kernel


def bivariate_generalized_Gaussian(kernel_size, sig_x, sig_y, theta, beta, grid=None, isotropic=True):
    """Generate a bivariate generalized Gaussian kernel.

    ``Paper: Parameter Estimation For Multivariate Generalized Gaussian Distributions``

    In the isotropic mode, only `sig_x` is used. `sig_y` and `theta` is ignored.

    Args:
        kernel_size (int):
        sig_x (float):
        sig_y (float):
        theta (float): Radian measurement.
        beta (float): shape parameter, beta = 1 is the normal distribution.
        grid (ndarray, optional): generated by :func:`mesh_grid`,
            with the shape (K, K, 2), K is the kernel size. Default: None

    Returns:
        kernel (ndarray): normalized kernel.
    """
    if grid is None:
        grid, _, _ = mesh_grid(kernel_size)
    if isotropic:
        sigma_matrix = np.array([[sig_x**2, 0], [0, sig_x**2]])
    else:
        sigma_matrix = sigma_matrix2(sig_x, sig_y, theta)
    inverse_sigma = np.linalg.inv(sigma_matrix)
    kernel = np.exp(-0.5 * np.power(np.sum(np.dot(grid, inverse_sigma) * grid, 2), beta))
    kernel = kernel / np.sum(kernel)
    return kernel


def bivariate_plateau(kernel_size, sig_x, sig_y, theta, beta, grid=None, isotropic=True):
    """Generate a plateau-like anisotropic kernel.

    1 / (1+x^(beta))

    Reference: https://stats.stackexchange.com/questions/203629/is-there-a-plateau-shaped-distribution

    In the isotropic mode, only `sig_x` is used. `sig_y` and `theta` is ignored.

    Args:
        kernel_size (int):
        sig_x (float):
        sig_y (float):
        theta (float): Radian measurement.
        beta (float): shape parameter, beta = 1 is the normal distribution.
        grid (ndarray, optional): generated by :func:`mesh_grid`,
            with the shape (K, K, 2), K is the kernel size. Default: None

    Returns:
        kernel (ndarray): normalized kernel.
    """
    if grid is None:
        grid, _, _ = mesh_grid(kernel_size)
    if isotropic:
        sigma_matrix = np.array([[sig_x**2, 0], [0, sig_x**2]])
    else:
        sigma_matrix = sigma_matrix2(sig_x, sig_y, theta)
    inverse_sigma = np.linalg.inv(sigma_matrix)
    kernel = np.reciprocal(np.power(np.sum(np.dot(grid, inverse_sigma) * grid, 2), beta) + 1)
    kernel = kernel / np.sum(kernel)
    return kernel


def random_bivariate_Gaussian(kernel_size,
                              sigma_x_range,
                              sigma_y_range,
                              rotation_range,
                              noise_range=None,
                              isotropic=True):
    """Randomly generate bivariate isotropic or anisotropic Gaussian kernels.

    In the isotropic mode, only `sigma_x_range` is used. `sigma_y_range` and `rotation_range` is ignored.

    Args:
        kernel_size (int):
        sigma_x_range (tuple): [0.6, 5]
        sigma_y_range (tuple): [0.6, 5]
        rotation range (tuple): [-math.pi, math.pi]
        noise_range(tuple, optional): multiplicative kernel noise,
            [0.75, 1.25]. Default: None

    Returns:
        kernel (ndarray):
    """
    assert kernel_size % 2 == 1, 'Kernel size must be an odd number.'
    assert sigma_x_range[0] < sigma_x_range[1], 'Wrong sigma_x_range.'
    sigma_x = np.random.uniform(sigma_x_range[0], sigma_x_range[1])
    if isotropic is False:
        assert sigma_y_range[0] < sigma_y_range[1], 'Wrong sigma_y_range.'
        assert rotation_range[0] < rotation_range[1], 'Wrong rotation_range.'
        sigma_y = np.random.uniform(sigma_y_range[0], sigma_y_range[1])
        rotation = np.random.uniform(rotation_range[0], rotation_range[1])
    else:
        sigma_y = sigma_x
        rotation = 0

    kernel = bivariate_Gaussian(kernel_size, sigma_x, sigma_y, rotation, isotropic=isotropic)

    # add multiplicative noise
    if noise_range is not None:
        assert noise_range[0] < noise_range[1], 'Wrong noise range.'
        noise = np.random.uniform(noise_range[0], noise_range[1], size=kernel.shape)
        kernel = kernel * noise
    kernel = kernel / np.sum(kernel)
    return kernel


def random_bivariate_generalized_Gaussian(kernel_size,
                                          sigma_x_range,
                                          sigma_y_range,
                                          rotation_range,
                                          beta_range,
                                          noise_range=None,
                                          isotropic=True):
    """Randomly generate bivariate generalized Gaussian kernels.

    In the isotropic mode, only `sigma_x_range` is used. `sigma_y_range` and `rotation_range` is ignored.

    Args:
        kernel_size (int):
        sigma_x_range (tuple): [0.6, 5]
        sigma_y_range (tuple): [0.6, 5]
        rotation range (tuple): [-math.pi, math.pi]
        beta_range (tuple): [0.5, 8]
        noise_range(tuple, optional): multiplicative kernel noise,
            [0.75, 1.25]. Default: None

    Returns:
        kernel (ndarray):
    """
    assert kernel_size % 2 == 1, 'Kernel size must be an odd number.'
    assert sigma_x_range[0] < sigma_x_range[1], 'Wrong sigma_x_range.'
    sigma_x = np.random.uniform(sigma_x_range[0], sigma_x_range[1])
    if isotropic is False:
        assert sigma_y_range[0] < sigma_y_range[1], 'Wrong sigma_y_range.'
        assert rotation_range[0] < rotation_range[1], 'Wrong rotation_range.'
        sigma_y = np.random.uniform(sigma_y_range[0], sigma_y_range[1])
        rotation = np.random.uniform(rotation_range[0], rotation_range[1])
    else:
        sigma_y = sigma_x
        rotation = 0

    # assume beta_range[0] < 1 < beta_range[1]
    if np.random.uniform() < 0.5:
        beta = np.random.uniform(beta_range[0], 1)
    else:
        beta = np.random.uniform(1, beta_range[1])

    kernel = bivariate_generalized_Gaussian(
        kernel_size, sigma_x, sigma_y, rotation, beta, isotropic=isotropic)

    # add multiplicative noise
    if noise_range is not None:
        assert noise_range[0] < noise_range[1], 'Wrong noise range.'
        noise = np.random.uniform(noise_range[0], noise_range[1], size=kernel.shape)
        kernel = kernel * noise
    kernel = kernel / np.sum(kernel)
    return kernel


def random_bivariate_plateau(kernel_size,
                             sigma_x_range,
                             sigma_y_range,
                             rotation_range,
                             beta_range,
                             noise_range=None,
                             isotropic=True):
    """Randomly generate bivariate plateau kernels.

    In the isotropic mode, only `sigma_x_range` is used. `sigma_y_range` and `rotation_range` is ignored.

    Args:
        kernel_size (int):
        sigma_x_range (tuple): [0.6, 5]
        sigma_y_range (tuple): [0.6, 5]
        rotation range (tuple): [-math.pi/2, math.pi/2]
        beta_range (tuple): [1, 4]
        noise_range(tuple, optional): multiplicative kernel noise,
            [0.75, 1.25]. Default: None

    Returns:
        kernel (ndarray):
    """
    assert kernel_size % 2 == 1, 'Kernel size must be an odd number.'
    assert sigma_x_range[0] < sigma_x_range[1], 'Wrong sigma_x_range.'
    sigma_x = np.random.uniform(sigma_x_range[0], sigma_x_range[1])
    if isotropic is False:
        assert sigma_y_range[0] < sigma_y_range[1], 'Wrong sigma_y_range.'
        assert rotation_range[0] < rotation_range[1], 'Wrong rotation_range.'
        sigma_y = np.random.uniform(sigma_y_range[0], sigma_y_range[1])
        rotation = np.random.uniform(rotation_range[0], rotation_range[1])
    else:
        sigma_y = sigma_x
        rotation = 0

    # TODO: this may be not proper
    if np.random.uniform() < 0.5:
        beta = np.random.uniform(beta_range[0], 1)
    else:
        beta = np.random.uniform(1, beta_range[1])

    kernel = bivariate_plateau(kernel_size, sigma_x, sigma_y, rotation, beta, isotropic=isotropic)
    # add multiplicative noise
    if noise_range is not None:
        assert noise_range[0] < noise_range[1], 'Wrong noise range.'
        noise = np.random.uniform(noise_range[0], noise_range[1], size=kernel.shape)
        kernel = kernel * noise
    kernel = kernel / np.sum(kernel)

    return kernel

########################################################################
########################################################################
########################################################################
# codes are modified from pyblur: https://github.com/lospooky/pyblur
from skimage.draw import line, disk

# defocus kernel
def defocus_kernel(kernel_size):
    kernel = np.zeros((kernel_size, kernel_size), dtype=np.float32)
    circleCenterCoord = kernel_size // 2
    circleRadius = circleCenterCoord + 1
    
    rr, cc = disk((circleCenterCoord, circleCenterCoord), circleRadius)
    kernel[rr, cc] = 1
    
    if(kernel_size == 3 or kernel_size == 5):
        kernel = Adjust(kernel, kernel_size)
        
    normalizationFactor = np.count_nonzero(kernel)
    kernel = kernel / normalizationFactor
    return kernel

def Adjust(kernel, kernel_size):
    kernel[0, 0] = 0
    kernel[0, kernel_size-1] = 0
    kernel[kernel_size-1, 0] = 0
    kernel[kernel_size-1, kernel_size-1] = 0 
    return kernel

# box kernel
def box_kernel(kernel_size):
    kernel = np.ones((kernel_size, kernel_size), dtype=np.float32)        
    normalizationFactor = np.count_nonzero(kernel)
    kernel = kernel / normalizationFactor
    return kernel

########## motion kernels ###########
# line motion kernel
def random_line_kernel(kernel_size):
    if kernel_size > 15: # to avoid over-large kernel
        kernel_size = kernel_size - 10 
    line_type = "full" # random.choice(["full", "right", "left"])
    line_angle = randomAngle(kernel_size)
    return line_kernel(kernel_size, line_angle, line_type)

def line_kernel(kernel_size, angle, linetype="full"):
    kernelCenter = int(kernel_size // 2)
    angle = SanitizeAngleValue(kernelCenter, angle)
    kernel = np.zeros((kernel_size, kernel_size), dtype=np.float32)
    lineDict = LineDictionary(kernel_size)
    lineAnchors = lineDict.lines[kernel_size][angle]

    if linetype == "right":
        lineAnchors[0] = kernelCenter
        lineAnchors[1] = kernelCenter
    if linetype == "left":
        lineAnchors[2] = kernelCenter
        lineAnchors[3] = kernelCenter

    rr, cc = line(lineAnchors[0], lineAnchors[1], lineAnchors[2], lineAnchors[3])
    kernel[rr, cc] = 1
    normalizationFactor = np.count_nonzero(kernel)
    kernel = kernel / normalizationFactor
    return kernel

def SanitizeAngleValue(kernelCenter, angle):
    numDistinctLines = kernelCenter * 4
    angle = math.fmod(angle, 180.0)
    validLineAngles = np.linspace(0, 180, numDistinctLines, endpoint=False)
    angle = nearestValue(angle, validLineAngles)
    return angle

def nearestValue(theta, validAngles):
    idx = (np.abs(validAngles - theta)).argmin()
    return validAngles[idx]

def randomAngle(kernel_size):
    kernelCenter = int(kernel_size // 2)
    numDistinctLines = kernelCenter * 4
    validLineAngles = np.linspace(0, 180, numDistinctLines, endpoint=False)
    angleIdx = np.random.randint(0, len(validLineAngles))
    return int(validLineAngles[angleIdx])

class LineDictionary:
    def __init__(self, n):
        self.lines = {}
        self.lines[n] = self.createNxNLines(n)

    def createNxNLines(self, n):
        assert (n - 1) % 2 == 0, "n must be a odd number!!!"
        lines = {}
        Num = 2 * n - 2
        angle_unit = 180.0 / Num
        cnt = 0
        a = int((n - 1) / 2)
        b = int((n + 1) / 2)

        for i in range(a, n):
            j = 0
            lines[cnt * angle_unit] = [i, j, n - 1 - i, n - 1 - j]
            cnt += 1
        for j in range(1, b):
            i = n - 1
            lines[cnt * angle_unit] = [i, j, n - 1 - i, n - 1 - j]
            cnt += 1
        for j in range(b, n):
            i = n - 1
            lines[cnt * angle_unit] = [n - 1 - i, n - 1 - j, i, j]
            cnt += 1
        for i in range(1, a):
            j = 0
            lines[cnt * angle_unit] = [i, j, n - 1 - i, n - 1 - j]
            cnt += 1
        return lines

# psf kernel
import pickle
pickledPsfFilename = os.path.join(os.path.dirname( __file__), "psf.pkl")

with open(pickledPsfFilename, 'rb') as pklfile:
    psfDictionary = pickle.load(pklfile, encoding='latin1')

def psf_kernel():
    return random.choice(psfDictionary)

########################################################################
########################################################################
########################################################################



def random_mixed_kernels(kernel_list,
                         kernel_prob,
                         kernel_size=21,
                         sigma_x_range=(0.6, 5),
                         sigma_y_range=(0.6, 5),
                         rotation_range=(-math.pi, math.pi),
                         betag_range=(0.5, 8),
                         betap_range=(0.5, 8),
                         noise_range=None):
    """Randomly generate mixed kernels.

    Args:
        kernel_list (tuple): a list name of kernel types,
            support ['iso', 'aniso', 'skew', 'generalized', 'plateau_iso',
            'plateau_aniso', 'defocus', 'box', 'line', 'psf']
        kernel_prob (tuple): corresponding kernel probability for each
            kernel type
        kernel_size (int):
        sigma_x_range (tuple): [0.6, 5]
        sigma_y_range (tuple): [0.6, 5]
        rotation range (tuple): [-math.pi, math.pi]
        beta_range (tuple): [0.5, 8]
        noise_range(tuple, optional): multiplicative kernel noise,
            [0.75, 1.25]. Default: None

    Returns:
        kernel (ndarray):
    """
    kernel_type = random.choices(kernel_list, kernel_prob)[0]
    if kernel_type == 'iso':
        kernel = random_bivariate_Gaussian(
            kernel_size, sigma_x_range, sigma_y_range, rotation_range, 
            noise_range=noise_range, isotropic=True)
    elif kernel_type == 'aniso':
        kernel = random_bivariate_Gaussian(
            kernel_size, sigma_x_range, sigma_y_range, rotation_range, 
            noise_range=noise_range, isotropic=False)
    elif kernel_type == 'generalized_iso':
        kernel = random_bivariate_generalized_Gaussian(
            kernel_size,
            sigma_x_range,
            sigma_y_range,
            rotation_range,
            betag_range,
            noise_range=noise_range,
            isotropic=True)
    elif kernel_type == 'generalized_aniso':
        kernel = random_bivariate_generalized_Gaussian(
            kernel_size,
            sigma_x_range,
            sigma_y_range,
            rotation_range,
            betag_range,
            noise_range=noise_range,
            isotropic=False)
    elif kernel_type == 'plateau_iso':
        kernel = random_bivariate_plateau(
            kernel_size, sigma_x_range, sigma_y_range, rotation_range, betap_range, 
            noise_range=None, isotropic=True)
    elif kernel_type == 'plateau_aniso':
        kernel = random_bivariate_plateau(
            kernel_size, sigma_x_range, sigma_y_range, rotation_range, betap_range, 
            noise_range=None, isotropic=False)
    elif kernel_type == 'defocus':
        kernel = defocus_kernel(kernel_size)
    elif kernel_type == 'box':
        kernel = box_kernel(kernel_size)
    elif kernel_type == 'line':
        kernel = random_line_kernel(kernel_size)
    elif kernel_type == 'psf':
        kernel = psf_kernel()

    return kernel


np.seterr(divide='ignore', invalid='ignore')


def circular_lowpass_kernel(cutoff, kernel_size, pad_to=0):
    """2D sinc filter

    Reference: https://dsp.stackexchange.com/questions/58301/2-d-circularly-symmetric-low-pass-filter

    Args:
        cutoff (float): cutoff frequency in radians (pi is max)
        kernel_size (int): horizontal and vertical size, must be odd.
        pad_to (int): pad kernel size to desired size, must be odd or zero.
    """
    assert kernel_size % 2 == 1, 'Kernel size must be an odd number.'
    kernel = np.fromfunction(
        lambda x, y: cutoff * special.j1(cutoff * np.sqrt(
            (x - (kernel_size - 1) / 2)**2 + (y - (kernel_size - 1) / 2)**2)) / (2 * np.pi * np.sqrt(
                (x - (kernel_size - 1) / 2)**2 + (y - (kernel_size - 1) / 2)**2)), 
            [kernel_size, kernel_size])
    kernel[(kernel_size - 1) // 2, (kernel_size - 1) // 2] = cutoff**2 / (4 * np.pi)
    kernel = kernel / np.sum(kernel)
    if pad_to > kernel_size:
        pad_size = (pad_to - kernel_size) // 2
        kernel = np.pad(kernel, ((pad_size, pad_size), (pad_size, pad_size)))
    return kernel


# ------------------------------------------------------------- #
# --------------------------- noise --------------------------- #
# ------------------------------------------------------------- #

# ----------------------- Gaussian Noise ----------------------- #


def generate_gaussian_noise(img, sigma=10, gray_noise=False):
    """Generate Gaussian noise.

    Args:
        img (Numpy array): Input image, shape (h, w, c), range [0, 1], float32.
        sigma (float): Noise scale (measured in range 255). Default: 10.

    Returns:
        (Numpy array): Returned noisy image, shape (h, w, c), range[0, 1],
            float32.
    """
    if gray_noise:
        noise = np.float32(np.random.randn(*(img.shape[0:2]))) * sigma / 255.
        noise = np.expand_dims(noise, axis=2).repeat(3, axis=2)
    else:
        noise = np.float32(np.random.randn(*(img.shape))) * sigma / 255.
    return noise


def add_gaussian_noise(img, sigma=10, clip=True, rounds=False, gray_noise=False):
    """Add Gaussian noise.

    Args:
        img (Numpy array): Input image, shape (h, w, c), range [0, 1], float32.
        sigma (float): Noise scale (measured in range 255). Default: 10.

    Returns:
        (Numpy array): Returned noisy image, shape (h, w, c), range[0, 1],
            float32.
    """
    noise = generate_gaussian_noise(img, sigma, gray_noise)
    out = img + noise
    if clip and rounds:
        out = np.clip((out * 255.0).round(), 0, 255) / 255.
    elif clip:
        out = np.clip(out, 0, 1)
    elif rounds:
        out = (out * 255.0).round() / 255.
    return out


def generate_gaussian_noise_pt(img, sigma=10, gray_noise=0):
    """Add Gaussian noise (PyTorch version).

    Args:
        img (Tensor): Shape (b, c, h, w), range[0, 1], float32.
        scale (float | Tensor): Noise scale. Default: 1.0.

    Returns:
        (Tensor): Returned noisy image, shape (b, c, h, w), range[0, 1],
            float32.
    """
    b, _, h, w = img.size()
    if not isinstance(sigma, (float, int)):
        sigma = sigma.view(img.size(0), 1, 1, 1)
    if isinstance(gray_noise, (float, int)):
        cal_gray_noise = gray_noise > 0
    else:
        gray_noise = gray_noise.view(b, 1, 1, 1)
        cal_gray_noise = torch.sum(gray_noise) > 0

    if cal_gray_noise:
        noise_gray = torch.randn(*img.size()[2:4], dtype=img.dtype, device=img.device) * sigma / 255.
        noise_gray = noise_gray.view(b, 1, h, w)

    # always calculate color noise
    noise = torch.randn(*img.size(), dtype=img.dtype, device=img.device) * sigma / 255.

    if cal_gray_noise:
        noise = noise * (1 - gray_noise) + noise_gray * gray_noise
    return noise


def add_gaussian_noise_pt(img, sigma=10, gray_noise=0, clip=True, rounds=False):
    """Add Gaussian noise (PyTorch version).

    Args:
        img (Tensor): Shape (b, c, h, w), range[0, 1], float32.
        scale (float | Tensor): Noise scale. Default: 1.0.

    Returns:
        (Tensor): Returned noisy image, shape (b, c, h, w), range[0, 1],
            float32.
    """
    noise = generate_gaussian_noise_pt(img, sigma, gray_noise)
    out = img + noise
    if clip and rounds:
        out = torch.clamp((out * 255.0).round(), 0, 255) / 255.
    elif clip:
        out = torch.clamp(out, 0, 1)
    elif rounds:
        out = (out * 255.0).round() / 255.
    return out


# ----------------------- Random Gaussian Noise ----------------------- #
def random_generate_gaussian_noise(img, sigma_range=(0, 10), gray_prob=0):
    sigma = np.random.uniform(sigma_range[0], sigma_range[1])
    if np.random.uniform() < gray_prob:
        gray_noise = True
    else:
        gray_noise = False
    return generate_gaussian_noise(img, sigma, gray_noise)


def random_add_gaussian_noise(img, sigma_range=(0, 1.0), gray_prob=0, clip=True, rounds=False):
    noise = random_generate_gaussian_noise(img, sigma_range, gray_prob)
    out = img + noise
    if clip and rounds:
        out = np.clip((out * 255.0).round(), 0, 255) / 255.
    elif clip:
        out = np.clip(out, 0, 1)
    elif rounds:
        out = (out * 255.0).round() / 255.
    return out


def random_generate_gaussian_noise_pt(img, sigma_range=(0, 10), gray_prob=0):
    sigma = torch.rand(
        img.size(0), 
        dtype=img.dtype, device=img.device) * (sigma_range[1] - sigma_range[0]) + sigma_range[0]
    gray_noise = torch.rand(img.size(0), dtype=img.dtype, device=img.device)
    gray_noise = (gray_noise < gray_prob).float()
    return generate_gaussian_noise_pt(img, sigma, gray_noise)


def random_add_gaussian_noise_pt(img, sigma_range=(0, 1.0), gray_prob=0, clip=True, rounds=False):
    noise = random_generate_gaussian_noise_pt(img, sigma_range, gray_prob)
    out = img + noise
    if clip and rounds:
        out = torch.clamp((out * 255.0).round(), 0, 255) / 255.
    elif clip:
        out = torch.clamp(out, 0, 1)
    elif rounds:
        out = (out * 255.0).round() / 255.
    return out


# ----------------------- Poisson (Shot) Noise ----------------------- #


def generate_poisson_noise(img, scale=1.0, gray_noise=False):
    """Generate poisson noise.

    Reference: https://github.com/scikit-image/scikit-image/blob/main/skimage/util/noise.py#L37-L219

    Args:
        img (Numpy array): Input image, shape (h, w, c), range [0, 1], float32.
        scale (float): Noise scale. Default: 1.0.
        gray_noise (bool): Whether generate gray noise. Default: False.

    Returns:
        (Numpy array): Returned noisy image, shape (h, w, c), range[0, 1],
            float32.
    """
    if gray_noise:
        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    # round and clip image for counting vals correctly
    img = np.clip((img * 255.0).round(), 0, 255) / 255.
    vals = len(np.unique(img))
    vals = 2**np.ceil(np.log2(vals))
    out = np.float32(np.random.poisson(img * vals) / float(vals))
    noise = out - img
    if gray_noise:
        noise = np.repeat(noise[:, :, np.newaxis], 3, axis=2)
    return noise * scale


def add_poisson_noise(img, scale=1.0, clip=True, rounds=False, gray_noise=False):
    """Add poisson noise.

    Args:
        img (Numpy array): Input image, shape (h, w, c), range [0, 1], float32.
        scale (float): Noise scale. Default: 1.0.
        gray_noise (bool): Whether generate gray noise. Default: False.

    Returns:
        (Numpy array): Returned noisy image, shape (h, w, c), range[0, 1],
            float32.
    """
    noise = generate_poisson_noise(img, scale, gray_noise)
    out = img + noise
    if clip and rounds:
        out = np.clip((out * 255.0).round(), 0, 255) / 255.
    elif clip:
        out = np.clip(out, 0, 1)
    elif rounds:
        out = (out * 255.0).round() / 255.
    return out


def generate_poisson_noise_pt(img, scale=1.0, gray_noise=0):
    """Generate a batch of poisson noise (PyTorch version)

    Args:
        img (Tensor): Input image, shape (b, c, h, w), range [0, 1], float32.
        scale (float | Tensor): Noise scale. Number or Tensor with shape (b).
            Default: 1.0.
        gray_noise (float | Tensor): 0-1 number or Tensor with shape (b).
            0 for False, 1 for True. Default: 0.

    Returns:
        (Tensor): Returned noisy image, shape (b, c, h, w), range[0, 1],
            float32.
    """
    b, _, h, w = img.size()
    if isinstance(gray_noise, (float, int)):
        cal_gray_noise = gray_noise > 0
    else:
        gray_noise = gray_noise.view(b, 1, 1, 1)
        cal_gray_noise = torch.sum(gray_noise) > 0
    if cal_gray_noise:
        img_gray = rgb_to_grayscale(img, num_output_channels=1)
        # round and clip image for counting vals correctly
        img_gray = torch.clamp((img_gray * 255.0).round(), 0, 255) / 255.
        # use for-loop to get the unique values for each sample
        vals_list = [len(torch.unique(img_gray[i, :, :, :])) for i in range(b)]
        vals_list = [2**np.ceil(np.log2(vals)) for vals in vals_list]
        vals = img_gray.new_tensor(vals_list).view(b, 1, 1, 1)
        out = torch.poisson(img_gray * vals) / vals
        noise_gray = out - img_gray
        noise_gray = noise_gray.expand(b, 3, h, w)

    # always calculate color noise
    # round and clip image for counting vals correctly
    img = torch.clamp((img * 255.0).round(), 0, 255) / 255.
    # use for-loop to get the unique values for each sample
    vals_list = [len(torch.unique(img[i, :, :, :])) for i in range(b)]
    vals_list = [2**np.ceil(np.log2(vals)) for vals in vals_list]
    vals = img.new_tensor(vals_list).view(b, 1, 1, 1)
    out = torch.poisson(img * vals) / vals
    noise = out - img
    if cal_gray_noise:
        noise = noise * (1 - gray_noise) + noise_gray * gray_noise
    if not isinstance(scale, (float, int)):
        scale = scale.view(b, 1, 1, 1)
    return noise * scale


def add_poisson_noise_pt(img, scale=1.0, clip=True, rounds=False, gray_noise=0):
    """Add poisson noise to a batch of images (PyTorch version).

    Args:
        img (Tensor): Input image, shape (b, c, h, w), range [0, 1], float32.
        scale (float | Tensor): Noise scale. Number or Tensor with shape (b).
            Default: 1.0.
        gray_noise (float | Tensor): 0-1 number or Tensor with shape (b).
            0 for False, 1 for True. Default: 0.

    Returns:
        (Tensor): Returned noisy image, shape (b, c, h, w), range[0, 1],
            float32.
    """
    noise = generate_poisson_noise_pt(img, scale, gray_noise)
    out = img + noise
    if clip and rounds:
        out = torch.clamp((out * 255.0).round(), 0, 255) / 255.
    elif clip:
        out = torch.clamp(out, 0, 1)
    elif rounds:
        out = (out * 255.0).round() / 255.
    return out


# ----------------------- Random Poisson (Shot) Noise ----------------------- #


def random_generate_poisson_noise(img, scale_range=(0, 1.0), gray_prob=0):
    scale = np.random.uniform(scale_range[0], scale_range[1])
    if np.random.uniform() < gray_prob:
        gray_noise = True
    else:
        gray_noise = False
    return generate_poisson_noise(img, scale, gray_noise)


def random_add_poisson_noise(img, scale_range=(0, 1.0), gray_prob=0, clip=True, rounds=False):
    noise = random_generate_poisson_noise(img, scale_range, gray_prob)
    out = img + noise
    if clip and rounds:
        out = np.clip((out * 255.0).round(), 0, 255) / 255.
    elif clip:
        out = np.clip(out, 0, 1)
    elif rounds:
        out = (out * 255.0).round() / 255.
    return out


def random_generate_poisson_noise_pt(img, scale_range=(0, 1.0), gray_prob=0):
    scale = torch.rand(
        img.size(0), 
        dtype=img.dtype, device=img.device) * (scale_range[1] - scale_range[0]) + scale_range[0]
    gray_noise = torch.rand(img.size(0), dtype=img.dtype, device=img.device)
    gray_noise = (gray_noise < gray_prob).float()
    return generate_poisson_noise_pt(img, scale, gray_noise)


def random_add_poisson_noise_pt(img, scale_range=(0, 1.0), gray_prob=0, clip=True, rounds=False):
    noise = random_generate_poisson_noise_pt(img, scale_range, gray_prob)
    out = img + noise
    if clip and rounds:
        out = torch.clamp((out * 255.0).round(), 0, 255) / 255.
    elif clip:
        out = torch.clamp(out, 0, 1)
    elif rounds:
        out = (out * 255.0).round() / 255.
    return out


# ------------------------------------------------------------------------ #
# --------------------------- JPEG compression --------------------------- #
# ------------------------------------------------------------------------ #


def add_jpg_compression(img, quality=90):
    """Add JPG compression artifacts.

    Args:
        img (Numpy array): Input image, shape (h, w, c), range [0, 1], float32.
        quality (float): JPG compression quality. 0 for lowest quality, 100 for
            best quality. Default: 90.

    Returns:
        (Numpy array): Returned image after JPG, shape (h, w, c), range[0, 1],
            float32.
    """
    img = np.clip(img, 0, 1)
    encode_param = [int(cv2.IMWRITE_JPEG_QUALITY), int(quality)]
    _, encimg = cv2.imencode('.jpg', img * 255., encode_param)
    img = np.float32(cv2.imdecode(encimg, 1)) / 255.
    return img


def random_add_jpg_compression(img, quality_range=(90, 100)):
    """Randomly add JPG compression artifacts.

    Args:
        img (Numpy array): Input image, shape (h, w, c), range [0, 1], float32.
        quality_range (tuple[float] | list[float]): JPG compression quality
            range. 0 for lowest quality, 100 for best quality.
            Default: (90, 100).

    Returns:
        (Numpy array): Returned image after JPG, shape (h, w, c), range[0, 1],
            float32.
    """
    quality = np.random.uniform(quality_range[0], quality_range[1])
    return add_jpg_compression(img, quality)



#################################################################
#################################################################
#################################################################

def usm_sharp(img, weight=0.5, radius=50, threshold=10):
    """USM sharpening.

    Input image: I; Blurry image: B.
    1. sharp = I + weight * (I - B)
    2. Mask = 1 if abs(I - B) > threshold, else: 0
    3. Blur mask:
    4. Out = Mask * sharp + (1 - Mask) * I

    Args:
        img (Numpy array): Input image, HWC, BGR; float32, [0, 1].
        weight (float): Sharp weight. Default: 1.
        radius (float): Kernel size of Gaussian blur. Default: 50.
        threshold (int):
    """
    radius = img.shape[0] // 5
    if radius % 2 == 0:
        radius += 1
    blur = cv2.GaussianBlur(img, (radius, radius), 0)
    residual = img - blur
    mask = np.abs(residual) * 255 > threshold
    mask = mask.astype('float32')
    soft_mask = cv2.GaussianBlur(mask, (radius, radius), 0)

    sharp = img + weight * residual
    sharp = np.clip(sharp, 0, 1)
    return soft_mask * sharp + (1 - soft_mask) * img

from scipy import fftpack

#wiener filter implementaion
def wiener_filter(img, kernel, K=0.006, pad_s=20):
    copy_img = np.pad(np.copy(img), pad_s, mode='symmetric')

    # pad kernel to avoid shift
    kernel /= np.sum(kernel)
    sz = (copy_img.shape[0] - kernel.shape[0], copy_img.shape[1] - kernel.shape[1])  # total amount of padding
    kernel = np.pad(kernel, (((sz[0]+1)//2, sz[0]//2), ((sz[1]+1)//2, sz[1]//2)), 'constant')
    kernel = fftpack.ifftshift(kernel)

    # wiener deconvolution
    kernel = fftpack.fft2(kernel)
    kernel = np.conj(kernel) / (np.abs(kernel) ** 2 + K)
    copy_img = np.real(fftpack.ifft2(fftpack.fft2(copy_img) * kernel))

    return copy_img[pad_s:-pad_s, pad_s:-pad_s]

def wiener_filter_multi_channel(img, kernel, K=0.006, pad_s=20):
    c_filtered = [wiener_filter(c, kernel) for c in cv2.split(img)]
    img_filtered = cv2.merge(c_filtered)
    return img_filtered


################################################################

pickledUCDPsfFilename = os.path.join(os.path.dirname( __file__), "ucdpsf.pkl")
with open(pickledUCDPsfFilename, 'rb') as pklfile:
    ucdpsfDictionary = pickle.load(pklfile, encoding='latin1')


def match_dim(data, dim):
    """
    Resize image dimensions using crop or padding instead of up/down-sampling.

    Args:
        data (np.array): single channel or 3 channel image array. 
            If 3-channel array (i.e. RGB), dimension -1 should be channels.
        dim (int, int): Desired dimensions for H, W. i.e dim = (H, W)

    Returns:
        np.array: Input image matched to new dimensions.
    """
    # Pad outer regions of detector
    if data.shape[0] < dim[0] or data.shape[1] < dim[1]:
        data = pad_edges(data, dim[:2])
    # Crop out edge regions outside detector dimensions     
    if data.shape[0] > dim[0] or data.shape[1] > dim[1]:
        data = center_crop(data, dim[:2])
    return data

def pad_edges(data, dim):
    """
    Pads H, W dimensions on outer edges to match desired dimensions if input dimension is lesser.
    If difference between input and output dimension shape is odd, 
    an additional pixel is added on the bottom/right padding.

    Args:
        data (np.array): single channel or 3 channel (i.e. RGB) image array. 
            If 3-channel array, dimension -1 should be channels
        dim (int, int): Desired dimensions for H, W. i.e dim = (H, W)

    Returns:
        np.array: Input image matched to new dimensions.
    """
    pad_h, pad_w = [max(dim[0] - data.shape[0], 0), 
                    max(dim[1] - data.shape[1], 0)]
    pad_top = pad_bot = pad_h // 2
    pad_left = pad_right = pad_w // 2
    
    if pad_h % 2 != 0:
        pad_bot += 1
    if pad_w % 2 != 0:
        pad_right += 1
    pad_tuple = ((pad_top, pad_bot), (pad_left, pad_right))
    if len(data.shape) == 3:
        pad_tuple = pad_tuple + ((0, 0),)
    return np.pad(data, pad_width=pad_tuple)

def center_crop(data, dim):
    """
    Crops center H, W dimensions to match desired dimensions if input dimension is greater.

    Args:
        data (np.array): single channel or 3-channel image array. 
        dim (int, int): Desired dimensions for H, W. i.e dim = (H, W)

    Returns:
        np.array: Input image matched to new dimensions.
    """
    h_start, w_start = [max(data.shape[0] - dim[0], 0) // 2,
                        max(data.shape[1] - dim[1], 0) // 2]
    h_end, w_end = [h_start + min(dim[0], data.shape[0]),
                    w_start + min(dim[1], data.shape[1])]
    return data[h_start:h_end, w_start:w_end]

def fft_filter(img, kernel):
    h, w = img.shape
    if kernel.shape[0] != img.shape[0] or kernel.shape[1] != img.shape[1]:
        kernel = match_dim(kernel, img.shape[:2])

    # FFT Convolution of image and PSF
    kernel = fftpack.ifftshift(kernel)
    kernel = fftpack.fft2(kernel)
    filtered_img = np.real(fftpack.ifft2(fftpack.fft2(img) * kernel))

    return filtered_img

def under_display_filter(img):
    kernel = random.choice(ucdpsfDictionary).transpose(2, 0, 1)
    c_filtered = [fft_filter(c, k) for c, k in zip(cv2.split(img), kernel)]
    img_filtered = cv2.merge(c_filtered)

    p = random.uniform(0.1, 0.5)
    img_filtered = img_filtered.astype(img.dtype)
    img_filtered = cv2.addWeighted(img_filtered, p, img, 1 - p, 0)

    np.clip((img_filtered * 255.0).round(), 0, 255) / 255.
    return img_filtered

################################################################

def doule_resize(img, s=1.1):
    h, w, _ = img.shape
    hs, ws = int(h*s), int(w*s)
    # interpolation = random.choice([cv2.INTER_AREA, cv2.INTER_CUBIC, cv2.INTER_LINEAR])
    interpolation = cv2.INTER_CUBIC
    resized = cv2.resize(img, (ws, hs), interpolation=interpolation)
    return cv2.resize(resized, (w, h), interpolation=interpolation)

def random_resize(img, hs=None, ws=None):
    if hs is None or ws is None:
        h, w, c = img.shape
        s = random.uniform(0.8, 1.4)
        hs, ws = int(h/s), int(w/s)
    interpolation = random.choice([cv2.INTER_AREA, cv2.INTER_CUBIC, cv2.INTER_LINEAR])
    return cv2.resize(img, (ws, hs), interpolation=interpolation)

# [0.45, 0.25, 0.12, 0.03, 0.12, 0.03]
def predefined_mixed_kernel(kernel_size=21):
    return random_mixed_kernels(
        ['iso', 'aniso', 'generalized_iso', 'generalized_aniso', 'plateau_iso', 'plateau_aniso',
         'defocus', 'box', 'line', 'psf'], 
        [0.25, 0.15, 0.1, 0.03, 0.1, 0.03, 0.15, 0.12, 0.04, 0.03], kernel_size=kernel_size,
        sigma_x_range=[0.2, 2.2], sigma_y_range=[0.2, 2.2],
        betag_range=(0.5, 2), betap_range=(1, 1.5), noise_range=[0.9, 1.1])

def predefined_sinc_kernel(kernel_size=21):
    if kernel_size < 13:
        omega_c = np.random.uniform(np.pi / 3, np.pi)
    else:
        omega_c = np.random.uniform(np.pi / 5, np.pi)
    return circular_lowpass_kernel(omega_c, kernel_size, pad_to=False)

def random_blur(img, max_radius=10, sinc_prob=0.1, deblur_prob=0.8, deg_list=None):
    kernel_range = [2 * v + 1 for v in range(2, max_radius)] # from 5 to 21
    kernel_size = random.choice(kernel_range)
    sinc_flag = random.random() < sinc_prob
    kernel = predefined_sinc_kernel(kernel_size) if sinc_flag \
                 else predefined_mixed_kernel(kernel_size)
    img = cv2.filter2D(img, -1, kernel)
    ori_img = img

    if deg_list is not None: deg_list.append('blur')
    if sinc_flag and deg_list is not None: deg_list.append('ringing artifact')

    if not sinc_flag and random.random() < deblur_prob and kernel_size < 8:
        img = wiener_filter_multi_channel(img, kernel)
        if deg_list is not None: deg_list.append('ringing artifact')

        img = img.astype(ori_img.dtype)
        # image blur blending
        if not sinc_flag and random.random() < 0.1:
            p = random.uniform(0.1, 0.5)
            img = cv2.addWeighted(ori_img, p, img, 1 - p, 0)

    return img

def random_noise(img, gauss_prob=0.6):
    if random.random() < gauss_prob:
        img = random_add_gaussian_noise(img, sigma_range=(1, 3), gray_prob=0.4)
    if random.random() < 1 - gauss_prob:
        img = random_add_poisson_noise(img, scale_range=(0.01, 0.3), gray_prob=0.4)

    img = np.clip((img * 255.0).round(), 0, 255).astype(np.uint8)
    # if random.random() < gauss_prob:
    #     h = random.choice([3, 5, 7, 9])
    #     filter_type = random.choice(['bilateral', 'nlm'])
    #     if filter_type == 'mean':
    #         img = cv2.blur(img, (h, h))
    #     elif filter_type == 'median':
    #         img = cv2.medianBlur(img, h)
    #     elif filter_type == 'gaussian':
    #         img = cv2.GaussianBlur(img, (h, h), 0)
    #     elif filter_type == 'bilateral':
    #         img = cv2.bilateralFilter(img, h, 15, 15)
    #     elif filter_type == 'nlm':
    #         img = cv2.fastNlMeansDenoising(img, None, h, 7, 21)

    return img / 255.


##########################################################
##########################################################

# ['blur', 'ringing artifact', 'noise', 'jpeg block']

def degrade(img, blur_prob=0.8, resize_prob=0.4, noise_prob=0.4, jpeg_prob=0.4, deg_list=None):
    if deg_list is None: deg_list = []
    h, w, c = img.shape

    degradations_first  = np.random.permutation(['blur', 'resize', 'noise', 'jpeg'])
    degradations_second = np.random.permutation(['blur', 'noise'])
    degradations_third  = np.random.permutation(['blur', 'resize', 'jpeg'])

    resize_flag = False
    if random.random() < resize_prob:
        resize_flag = True

    ### first order
    for deg_type in degradations_first:
        if deg_type == 'blur' and random.random() < blur_prob:
            img = random_blur(img, max_radius=10, sinc_prob=0.1, deblur_prob=0.4, deg_list=deg_list)
        elif deg_type == 'blur' and random.random() < 0.2:
            img = under_display_filter(img)

        elif deg_type == 'resize' and resize_flag:
            deg_list.append('blur')
            img = random_resize(img)
        elif deg_type == 'noise' and random.random() < noise_prob:
            deg_list.append('noise')
            img = random_noise(img.astype('float32'))
        elif deg_type == 'jpeg' and random.random() < jpeg_prob:
            deg_list.append('jpeg block')
            img = random_add_jpg_compression(img, quality_range=(60, 95))
        
    ### second order
    for deg_type in degradations_second:
        if deg_type == 'blur' and random.random() < blur_prob:
            img = random_blur(img, max_radius=5, sinc_prob=0.1, deblur_prob=0.4, deg_list=deg_list)
        elif deg_type == 'blur' and random.random() < 0.2:
            img = under_display_filter(img)

        elif deg_type == 'noise' and random.random() < noise_prob:
            deg_list.append('noise')
            img = random_noise(img.astype('float32'))

    ### third order
    for deg_type in degradations_third:
        if deg_type == 'blur' and random.random() < blur_prob:
            img = random_blur(img, max_radius=10, sinc_prob=0.9, deblur_prob=0.5, deg_list=deg_list)
        elif deg_type == 'resize' and resize_flag:
            deg_list.append('blur')
            img = random_resize(img, hs=h, ws=w)
        elif deg_type == 'jpeg' and random.random() < jpeg_prob:
            deg_list.append('jpeg block')
            img = random_add_jpg_compression(img, quality_range=(80, 100))

    return np.clip((img * 255.0).round(), 0, 255) / 255.


def random_degrade(img, blur_prob=0.8, resize_prob=0.4, noise_prob=0.4, jpeg_prob=0.4, deg_list=None):
    return degrade(img, blur_prob=blur_prob, resize_prob=resize_prob, noise_prob=noise_prob, jpeg_prob=jpeg_prob, deg_list=deg_list)


def domain_adapting(img, s=1.1, sigma=1, quality=95, interpolation=cv2.INTER_LINEAR):
    h, w = img.shape[0], img.shape[1]
    hs, ws = int(h*s), int(w*s)
    img = add_gaussian_noise(img, sigma=sigma)
    img = cv2.resize(img, (ws, hs), interpolation=interpolation)
    img = add_jpg_compression(img, quality)
    return cv2.resize(img, (w, h), interpolation=interpolation)




